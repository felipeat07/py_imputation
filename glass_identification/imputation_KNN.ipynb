{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6bc7e73",
   "metadata": {},
   "source": [
    "### Estratégia de Imputação KNN com Ponderação por Eta²\n",
    "\n",
    "####  Objetivo\n",
    "Imputar valores ausentes na variável categórica `Type_of_glass`, utilizando as variáveis numéricas como base, com um **KNN personalizado** que utiliza pesos derivados da **associação estatística (Eta²)**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Etapas da Abordagem\n",
    "\n",
    "##### 1. Simulação de valores ausentes:\n",
    "- Gerar valores ausentes de forma **MCAR** (*Missing Completely At Random*) na coluna `Type_of_glass`.\n",
    "\n",
    "##### 2. Cálculo do Eta² (*Eta Squared*):\n",
    "- Para cada variável numérica, calcular o **eta quadrado** em relação a `Type_of_glass`.\n",
    "- O **eta² quantifica a associação** entre a variável numérica e a categórica.\n",
    "- Valores mais altos indicam **maior poder preditivo**.\n",
    "\n",
    "##### 3. Pré-processamento dos dados:\n",
    "- **Normalizar** todas as variáveis numéricas (ex: Min-Max ou Z-score);\n",
    "- **Multiplicar** cada variável normalizada pelo seu **eta²**, criando uma **representação ponderada dos dados**.\n",
    "\n",
    "##### 4. Imputação via KNN personalizado:\n",
    "Para cada linha com `Type_of_glass` ausente:\n",
    "- Calcular a **distância** (ex: Euclidiana ou Gower ponderada) entre essa linha e as outras com `Type_of_glass` conhecido;\n",
    "- Selecionar os **k vizinhos mais próximos**;\n",
    "- Imputar com a **moda** dos `Type_of_glass` entre esses vizinhos.\n",
    "\n",
    "---\n",
    "\n",
    "#### Vantagens da Abordagem\n",
    "- Leva em conta **quais variáveis são mais relevantes** para prever `Type_of_glass`;\n",
    "- Melhora a qualidade da imputação comparado a **KNN simples** ou **imputação por moda global**;\n",
    "- É especialmente útil quando só há **uma variável categórica e muitas numéricas**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf69da1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto da imputação: 0.7143 (71.43%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.spatial.distance import cdist\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# 1. Carregar e preparar os dados\n",
    "file_path = 'data/glass.data'\n",
    "columns = ['Id', 'RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type_of_glass']\n",
    "\n",
    "df = pd.read_csv(file_path, header=None, names=columns)\n",
    "df.drop(columns=['Id'], inplace=True)\n",
    "\n",
    "# Salvar os dados originais para avaliação\n",
    "df_original = df.copy()\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# 2. Inserir valores ausentes (MCAR) em Type_of_glass\n",
    "missing_frac = 0.2\n",
    "n_missing = int(missing_frac * len(df))\n",
    "missing_indices = random.sample(list(df.index), n_missing)\n",
    "df.loc[missing_indices, 'Type_of_glass'] = np.nan\n",
    "\n",
    "# 3. Calcular o Eta² para cada variável numérica em relação a Type_of_glass\n",
    "def eta_squared(x, y):\n",
    "    classes = y.dropna().unique()\n",
    "    grand_mean = x[y.notna()].mean()\n",
    "    ss_between = sum([\n",
    "        len(x[y == cl]) * ((x[y == cl].mean() - grand_mean) ** 2)\n",
    "        for cl in classes\n",
    "    ])\n",
    "    ss_total = sum((x[y.notna()] - grand_mean) ** 2)\n",
    "    return ss_between / ss_total if ss_total != 0 else 0\n",
    "\n",
    "numerical_cols = df.columns.drop('Type_of_glass')\n",
    "etas = {col: eta_squared(df[col], df['Type_of_glass']) for col in numerical_cols}\n",
    "etas_series = pd.Series(etas)\n",
    "\n",
    "# 4. Normalizar e aplicar pesos Eta²\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df[numerical_cols]), columns=numerical_cols)\n",
    "df_weighted = df_scaled * etas_series\n",
    "\n",
    "# 5. Função de imputação com KNN usando distância euclidiana\n",
    "def knn_impute(row_idx, df_weighted, df_target, k=5):\n",
    "    row = df_weighted.iloc[row_idx].values.reshape(1, -1)\n",
    "\n",
    "    # Seleciona apenas amostras conhecidas\n",
    "    df_known = df_weighted[df_target.notna()]\n",
    "    target_known = df_target[df_target.notna()]\n",
    "\n",
    "    if df_known.empty:\n",
    "        return target_known.mode().iloc[0]\n",
    "\n",
    "    distances = cdist(row, df_known.values, metric='euclidean').flatten()\n",
    "    nearest_indices = df_known.index[np.argsort(distances)[:k]]\n",
    "    nearest_labels = target_known.loc[nearest_indices].dropna()\n",
    "\n",
    "    if nearest_labels.empty:\n",
    "        return target_known.mode().iloc[0]\n",
    "\n",
    "    return Counter(nearest_labels).most_common(1)[0][0]\n",
    "\n",
    "# 6. Aplicar imputação\n",
    "df_imputed = df['Type_of_glass'].copy()\n",
    "missing_mask = df_imputed.isna()\n",
    "\n",
    "for idx in df[missing_mask].index:\n",
    "    df_imputed[idx] = knn_impute(idx, df_weighted, df['Type_of_glass'])\n",
    "\n",
    "# 7. Avaliação da Imputação\n",
    "true_values = df_original.loc[missing_indices, 'Type_of_glass']\n",
    "predicted_values = df_imputed.loc[missing_indices]\n",
    "acuracia = accuracy_score(true_values, predicted_values)\n",
    "\n",
    "print(f\"Taxa de acerto da imputação: {acuracia:.4f} ({acuracia * 100:.2f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeb6ea0",
   "metadata": {},
   "source": [
    "#### Pipeline Alternativa: KNN Simples (Sem Eta²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf848ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto com KNN simples (sem Eta²): 0.6905 (69.05%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.spatial.distance import cdist\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# 1. Carregar e preparar os dados\n",
    "file_path = 'data/glass.data'\n",
    "columns = ['Id', 'RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type_of_glass']\n",
    "\n",
    "df = pd.read_csv(file_path, header=None, names=columns)\n",
    "df.drop(columns=['Id'], inplace=True)\n",
    "\n",
    "# Salvar os dados originais para avaliação\n",
    "df_original = df.copy()\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# 2. Inserir valores ausentes (MCAR) em Type_of_glass\n",
    "missing_frac = 0.2\n",
    "n_missing = int(missing_frac * len(df))\n",
    "missing_indices = random.sample(list(df.index), n_missing)\n",
    "df.loc[missing_indices, 'Type_of_glass'] = np.nan\n",
    "\n",
    "# 3. Normalizar os dados (sem ponderar por Eta²)\n",
    "numerical_cols = df.columns.drop('Type_of_glass')\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df[numerical_cols]), columns=numerical_cols)\n",
    "\n",
    "# 4. Função de imputação com KNN simples (não ponderado)\n",
    "def knn_impute_simple(row_idx, df_scaled, df_target, k=5):\n",
    "    row = df_scaled.iloc[row_idx].values.reshape(1, -1)\n",
    "\n",
    "    df_known = df_scaled[df_target.notna()]\n",
    "    target_known = df_target[df_target.notna()]\n",
    "\n",
    "    if df_known.empty:\n",
    "        return target_known.mode().iloc[0]\n",
    "\n",
    "    distances = cdist(row, df_known.values, metric='euclidean').flatten()\n",
    "    nearest_indices = df_known.index[np.argsort(distances)[:k]]\n",
    "    nearest_labels = target_known.loc[nearest_indices].dropna()\n",
    "\n",
    "    if nearest_labels.empty:\n",
    "        return target_known.mode().iloc[0]\n",
    "\n",
    "    return Counter(nearest_labels).most_common(1)[0][0]\n",
    "\n",
    "# 5. Aplicar imputação\n",
    "df_imputed_simple = df['Type_of_glass'].copy()\n",
    "missing_mask = df_imputed_simple.isna()\n",
    "\n",
    "for idx in df[missing_mask].index:\n",
    "    df_imputed_simple[idx] = knn_impute_simple(idx, df_scaled, df['Type_of_glass'])\n",
    "\n",
    "# 6. Avaliação da Imputação\n",
    "true_values = df_original.loc[missing_indices, 'Type_of_glass']\n",
    "predicted_values_simple = df_imputed_simple.loc[missing_indices]\n",
    "acuracia_simple = accuracy_score(true_values, predicted_values_simple)\n",
    "\n",
    "print(f\"Taxa de acerto com KNN simples (sem Eta²): {acuracia_simple:.4f} ({acuracia_simple * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fd3cd8",
   "metadata": {},
   "source": [
    "### KNN com Gower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6d18fdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto com KNN + Gower: 0.7143 (71.43%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# 1. Carregar e preparar os dados\n",
    "file_path = 'data/glass.data'\n",
    "columns = ['Id', 'RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type_of_glass']\n",
    "\n",
    "df = pd.read_csv(file_path, header=None, names=columns)\n",
    "df.drop(columns=['Id'], inplace=True)\n",
    "\n",
    "# Salvar os dados originais para avaliação\n",
    "df_original = df.copy()\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# 2. Inserir valores ausentes (MCAR) em Type_of_glass\n",
    "missing_frac = 0.2\n",
    "n_missing = int(missing_frac * len(df))\n",
    "missing_indices = random.sample(list(df.index), n_missing)\n",
    "df.loc[missing_indices, 'Type_of_glass'] = np.nan\n",
    "\n",
    "# 3. Calcular distância de Gower (numérica apenas)\n",
    "def gower_distance_matrix(X):\n",
    "    X = X.copy()\n",
    "    ranges = X.max() - X.min()\n",
    "    X_norm = (X - X.min()) / ranges\n",
    "    n = X.shape[0]\n",
    "    dist_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        dist_matrix[i] = np.abs(X_norm.values[i] - X_norm.values).mean(axis=1)\n",
    "    return dist_matrix\n",
    "\n",
    "numerical_cols = df.columns.drop('Type_of_glass')\n",
    "df_numeric = df[numerical_cols]\n",
    "\n",
    "# Pré-calcular matriz de distâncias Gower (linha x linha)\n",
    "gower_matrix = gower_distance_matrix(df_numeric)\n",
    "\n",
    "# 4. Imputação com Gower\n",
    "def knn_impute_gower(row_idx, gower_matrix, df_target, k=5):\n",
    "    # Distâncias da linha atual para todas as outras\n",
    "    distances = gower_matrix[row_idx]\n",
    "    \n",
    "    # Excluir os que também estão ausentes\n",
    "    known_mask = df_target.notna().values\n",
    "    distances_known = distances[known_mask]\n",
    "    indices_known = np.where(known_mask)[0]\n",
    "\n",
    "    if len(indices_known) == 0:\n",
    "        return df_target.mode().iloc[0]\n",
    "\n",
    "    # Selecionar os k mais próximos\n",
    "    nearest_idxs = indices_known[np.argsort(distances_known)[:k]]\n",
    "    nearest_labels = df_target.iloc[nearest_idxs].dropna()\n",
    "\n",
    "    if nearest_labels.empty:\n",
    "        return df_target.mode().iloc[0]\n",
    "\n",
    "    return Counter(nearest_labels).most_common(1)[0][0]\n",
    "\n",
    "# 5. Aplicar imputação\n",
    "df_imputed_gower = df['Type_of_glass'].copy()\n",
    "missing_mask = df_imputed_gower.isna()\n",
    "\n",
    "for idx in df[missing_mask].index:\n",
    "    df_imputed_gower[idx] = knn_impute_gower(idx, gower_matrix, df['Type_of_glass'])\n",
    "\n",
    "# 6. Avaliação da Imputação\n",
    "true_values = df_original.loc[missing_indices, 'Type_of_glass']\n",
    "predicted_values_gower = df_imputed_gower.loc[missing_indices]\n",
    "acuracia_gower = accuracy_score(true_values, predicted_values_gower)\n",
    "\n",
    "print(f\"Taxa de acerto com KNN + Gower: {acuracia_gower:.4f} ({acuracia_gower * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b7e4c2",
   "metadata": {},
   "source": [
    "### Variando os Seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9451ed3",
   "metadata": {},
   "source": [
    "Seed (Semente) do Random:\n",
    "- É um valor inicial que controla a geração de números aleatórios no código. Definir a seed garante que os resultados sejam reproduzíveis — ou seja, que o processo aleatório aconteça da mesma forma toda vez que rodar.\n",
    "\n",
    "Por que variar a seed?\n",
    "- Como a inserção dos valores ausentes é aleatória, diferentes seeds geram diferentes padrões de dados faltantes, impactando a performance da imputação. Avaliar os métodos KNN em várias seeds permite medir a robustez e a consistência de cada técnica, fornecendo uma comparação mais confiável do desempenho médio e sua variação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1e671c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executando seed 10...\n",
      "Executando seed 11...\n",
      "Executando seed 12...\n",
      "Executando seed 13...\n",
      "Executando seed 14...\n",
      "Executando seed 15...\n",
      "Executando seed 16...\n",
      "Executando seed 17...\n",
      "Executando seed 18...\n",
      "Executando seed 19...\n",
      "Executando seed 20...\n",
      "Executando seed 21...\n",
      "Executando seed 22...\n",
      "Executando seed 23...\n",
      "Executando seed 24...\n",
      "Executando seed 25...\n",
      "Executando seed 26...\n",
      "Executando seed 27...\n",
      "Executando seed 28...\n",
      "Executando seed 29...\n",
      "Executando seed 30...\n",
      "Executando seed 31...\n",
      "Executando seed 32...\n",
      "Executando seed 33...\n",
      "Executando seed 34...\n",
      "Executando seed 35...\n",
      "Executando seed 36...\n",
      "Executando seed 37...\n",
      "Executando seed 38...\n",
      "Executando seed 39...\n",
      "\n",
      "Resumo dos resultados (média e std das acurácias):\n",
      "           seed  weighted    simple     gower\n",
      "mean  24.500000  0.672222  0.664286  0.706349\n",
      "std    8.803408  0.065185  0.056741  0.056735\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.spatial.distance import cdist\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# --- Funções auxiliares ---\n",
    "\n",
    "def eta_squared(x, y):\n",
    "    classes = y.dropna().unique()\n",
    "    grand_mean = x[y.notna()].mean()\n",
    "    ss_between = sum([\n",
    "        len(x[y == cl]) * ((x[y == cl].mean() - grand_mean) ** 2)\n",
    "        for cl in classes\n",
    "    ])\n",
    "    ss_total = sum((x[y.notna()] - grand_mean) ** 2)\n",
    "    return ss_between / ss_total if ss_total != 0 else 0\n",
    "\n",
    "def gower_distance_matrix(X):\n",
    "    X = X.copy()\n",
    "    ranges = X.max() - X.min()\n",
    "    X_norm = (X - X.min()) / ranges\n",
    "    n = X.shape[0]\n",
    "    dist_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        dist_matrix[i] = np.abs(X_norm.values[i] - X_norm.values).mean(axis=1)\n",
    "    return dist_matrix\n",
    "\n",
    "def knn_impute(row_idx, df_weighted, df_target, k=5):\n",
    "    row = df_weighted.iloc[row_idx].values.reshape(1, -1)\n",
    "    df_known = df_weighted[df_target.notna()]\n",
    "    target_known = df_target[df_target.notna()]\n",
    "    if df_known.empty:\n",
    "        return target_known.mode().iloc[0]\n",
    "    distances = cdist(row, df_known.values, metric='euclidean').flatten()\n",
    "    nearest_indices = df_known.index[np.argsort(distances)[:k]]\n",
    "    nearest_labels = target_known.loc[nearest_indices].dropna()\n",
    "    if nearest_labels.empty:\n",
    "        return target_known.mode().iloc[0]\n",
    "    return Counter(nearest_labels).most_common(1)[0][0]\n",
    "\n",
    "def knn_impute_simple(row_idx, df_scaled, df_target, k=5):\n",
    "    row = df_scaled.iloc[row_idx].values.reshape(1, -1)\n",
    "    df_known = df_scaled[df_target.notna()]\n",
    "    target_known = df_target[df_target.notna()]\n",
    "    if df_known.empty:\n",
    "        return target_known.mode().iloc[0]\n",
    "    distances = cdist(row, df_known.values, metric='euclidean').flatten()\n",
    "    nearest_indices = df_known.index[np.argsort(distances)[:k]]\n",
    "    nearest_labels = target_known.loc[nearest_indices].dropna()\n",
    "    if nearest_labels.empty:\n",
    "        return target_known.mode().iloc[0]\n",
    "    return Counter(nearest_labels).most_common(1)[0][0]\n",
    "\n",
    "def knn_impute_gower(row_idx, gower_matrix, df_target, k=5):\n",
    "    distances = gower_matrix[row_idx]\n",
    "    known_mask = df_target.notna().values\n",
    "    distances_known = distances[known_mask]\n",
    "    indices_known = np.where(known_mask)[0]\n",
    "    if len(indices_known) == 0:\n",
    "        return df_target.mode().iloc[0]\n",
    "    nearest_idxs = indices_known[np.argsort(distances_known)[:k]]\n",
    "    nearest_labels = df_target.iloc[nearest_idxs].dropna()\n",
    "    if nearest_labels.empty:\n",
    "        return df_target.mode().iloc[0]\n",
    "    return Counter(nearest_labels).most_common(1)[0][0]\n",
    "\n",
    "# --- Pipeline que executa um experimento com um seed fixo ---\n",
    "\n",
    "def run_experiment(seed, missing_frac=0.2, k=5):\n",
    "    # 1. Carregar e preparar os dados\n",
    "    file_path = 'data/glass.data'\n",
    "    columns = ['Id', 'RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type_of_glass']\n",
    "    df = pd.read_csv(file_path, header=None, names=columns)\n",
    "    df.drop(columns=['Id'], inplace=True)\n",
    "    df_original = df.copy()\n",
    "\n",
    "    # Fixar seed para reproducibilidade do missing\n",
    "    random.seed(seed)\n",
    "\n",
    "    # 2. Inserir valores ausentes MCAR\n",
    "    n_missing = int(missing_frac * len(df))\n",
    "    missing_indices = random.sample(list(df.index), n_missing)\n",
    "    df.loc[missing_indices, 'Type_of_glass'] = np.nan\n",
    "\n",
    "    # Colunas numéricas\n",
    "    numerical_cols = df.columns.drop('Type_of_glass')\n",
    "\n",
    "    # 3. KNN com Eta² ponderado + Euclidiana\n",
    "    etas = {col: eta_squared(df[col], df['Type_of_glass']) for col in numerical_cols}\n",
    "    etas_series = pd.Series(etas)\n",
    "    scaler = MinMaxScaler()\n",
    "    df_scaled = pd.DataFrame(scaler.fit_transform(df[numerical_cols]), columns=numerical_cols)\n",
    "    df_weighted = df_scaled * etas_series\n",
    "\n",
    "    df_imputed = df['Type_of_glass'].copy()\n",
    "    for idx in df_imputed[df_imputed.isna()].index:\n",
    "        df_imputed[idx] = knn_impute(idx, df_weighted, df['Type_of_glass'], k=k)\n",
    "\n",
    "    acc_weighted = accuracy_score(df_original.loc[missing_indices, 'Type_of_glass'], df_imputed.loc[missing_indices])\n",
    "\n",
    "    # 4. KNN simples (sem Eta²) + Euclidiana\n",
    "    df_scaled_simple = pd.DataFrame(scaler.fit_transform(df[numerical_cols]), columns=numerical_cols)\n",
    "\n",
    "    df_imputed_simple = df['Type_of_glass'].copy()\n",
    "    for idx in df_imputed_simple[df_imputed_simple.isna()].index:\n",
    "        df_imputed_simple[idx] = knn_impute_simple(idx, df_scaled_simple, df['Type_of_glass'], k=k)\n",
    "\n",
    "    acc_simple = accuracy_score(df_original.loc[missing_indices, 'Type_of_glass'], df_imputed_simple.loc[missing_indices])\n",
    "\n",
    "    # 5. KNN com distância de Gower\n",
    "    df_numeric = df[numerical_cols]\n",
    "    gower_matrix = gower_distance_matrix(df_numeric)\n",
    "\n",
    "    df_imputed_gower = df['Type_of_glass'].copy()\n",
    "    for idx in df_imputed_gower[df_imputed_gower.isna()].index:\n",
    "        df_imputed_gower[idx] = knn_impute_gower(idx, gower_matrix, df['Type_of_glass'], k=k)\n",
    "\n",
    "    acc_gower = accuracy_score(df_original.loc[missing_indices, 'Type_of_glass'], df_imputed_gower.loc[missing_indices])\n",
    "\n",
    "    return acc_weighted, acc_simple, acc_gower\n",
    "\n",
    "# --- Executar vários experimentos ---\n",
    "\n",
    "seeds = list(range(10, 40))  # 30 execuções, seeds de 10 a 39\n",
    "results = []\n",
    "\n",
    "for s in seeds:\n",
    "    print(f\"Executando seed {s}...\")\n",
    "    acc_w, acc_s, acc_g = run_experiment(s)\n",
    "    results.append({'seed': s, 'weighted': acc_w, 'simple': acc_s, 'gower': acc_g})\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# --- Resultados resumidos ---\n",
    "summary = df_results.describe().loc[['mean', 'std']]\n",
    "print(\"\\nResumo dos resultados (média e std das acurácias):\")\n",
    "print(summary)\n",
    "\n",
    "# --- Você pode ainda exportar os resultados para CSV para análises futuras ---\n",
    "# df_results.to_csv('knn_imputation_comparison_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1032670",
   "metadata": {},
   "source": [
    "Média (mean):\n",
    "- É a média da taxa de acerto (accuracy) da imputação para cada método, calculada ao longo das 30 execuções com seeds diferentes.\n",
    "Exemplo: O método com distância de Gower tem uma média de acurácia de ~70,6%, maior que os outros dois.\n",
    "\n",
    "Desvio padrão (std):\n",
    "- Mede a variabilidade das acurácias entre diferentes seeds. Quanto menor o desvio padrão, mais consistente é o desempenho do método em diferentes execuções.\n",
    "Aqui os desvios padrões são semelhantes entre os métodos, em torno de 5.6% a 6.5%.\n",
    "\n",
    "Insights:\n",
    "- Melhor acurácia média: O método KNN + Gower (0.7063) teve a melhor média, sugerindo que usar a distância de Gower ajuda a imputar melhor para esse dataset.\n",
    "\n",
    "- Consistência: Todos os métodos apresentam uma variação considerável (~5-6% de std), o que mostra que o desempenho depende bastante da amostra gerada (seed).\n",
    "\n",
    "- Diferenças pequenas entre Weighted e Simple: O método ponderado por Eta² ficou um pouco melhor que o simples, mas essa diferença não é tão grande.\n",
    "\n",
    "- Importância de testar vários seeds: Como a acurácia varia, um único seed pode não ser representativo. Avaliar média e desvio é importante para conclusões confiáveis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
