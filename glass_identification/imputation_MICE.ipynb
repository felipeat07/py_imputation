{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6623794e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# 7. Imputar usando IterativeImputer com RandomForestClassifier\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Como é categórico, usamos Round para garantir valores inteiros\u001b[39;00m\n\u001b[32m     41\u001b[39m imputer = IterativeImputer(estimator=RandomForestClassifier(), \n\u001b[32m     42\u001b[39m                            max_iter=\u001b[32m10\u001b[39m, random_state=\u001b[32m42\u001b[39m, \n\u001b[32m     43\u001b[39m                            sample_posterior=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m df_imp_imputed = \u001b[43mimputer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_imp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# 8. Recuperar o dataframe com imputação aplicada\u001b[39;00m\n\u001b[32m     48\u001b[39m df_imputed = pd.DataFrame(df_imp_imputed, columns=df_imp.columns)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projetos/py_imputation/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projetos/py_imputation/.venv/lib/python3.12/site-packages/sklearn/base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projetos/py_imputation/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:859\u001b[39m, in \u001b[36mIterativeImputer.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    855\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m feat_idx \u001b[38;5;129;01min\u001b[39;00m ordered_idx:\n\u001b[32m    856\u001b[39m     neighbor_feat_idx = \u001b[38;5;28mself\u001b[39m._get_neighbor_feat_idx(\n\u001b[32m    857\u001b[39m         n_features, feat_idx, abs_corr_mat\n\u001b[32m    858\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m     Xt, estimator = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_impute_one_feature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m        \u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmask_missing_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeat_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneighbor_feat_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    868\u001b[39m     estimator_triplet = _ImputerTriplet(\n\u001b[32m    869\u001b[39m         feat_idx, neighbor_feat_idx, estimator\n\u001b[32m    870\u001b[39m     )\n\u001b[32m    871\u001b[39m     \u001b[38;5;28mself\u001b[39m.imputation_sequence_.append(estimator_triplet)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projetos/py_imputation/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:427\u001b[39m, in \u001b[36mIterativeImputer._impute_one_feature\u001b[39m\u001b[34m(self, X_filled, mask_missing_values, feat_idx, neighbor_feat_idx, estimator, fit_mode, params)\u001b[39m\n\u001b[32m    417\u001b[39m     X_train = _safe_indexing(\n\u001b[32m    418\u001b[39m         _safe_indexing(X_filled, neighbor_feat_idx, axis=\u001b[32m1\u001b[39m),\n\u001b[32m    419\u001b[39m         ~missing_row_mask,\n\u001b[32m    420\u001b[39m         axis=\u001b[32m0\u001b[39m,\n\u001b[32m    421\u001b[39m     )\n\u001b[32m    422\u001b[39m     y_train = _safe_indexing(\n\u001b[32m    423\u001b[39m         _safe_indexing(X_filled, feat_idx, axis=\u001b[32m1\u001b[39m),\n\u001b[32m    424\u001b[39m         ~missing_row_mask,\n\u001b[32m    425\u001b[39m         axis=\u001b[32m0\u001b[39m,\n\u001b[32m    426\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[38;5;66;03m# if no missing values, don't predict\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.sum(missing_row_mask) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projetos/py_imputation/.venv/lib/python3.12/site-packages/sklearn/base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projetos/py_imputation/.venv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:418\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    411\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    412\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSum of y is not strictly positive which \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    413\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mis necessary for Poisson regression.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    414\u001b[39m         )\n\u001b[32m    416\u001b[39m \u001b[38;5;28mself\u001b[39m._n_samples, \u001b[38;5;28mself\u001b[39m.n_outputs_ = y.shape\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m y, expanded_class_weight = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_y_class_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(y, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) != DOUBLE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y.flags.contiguous:\n\u001b[32m    421\u001b[39m     y = np.ascontiguousarray(y, dtype=DOUBLE)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projetos/py_imputation/.venv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:830\u001b[39m, in \u001b[36mForestClassifier._validate_y_class_weight\u001b[39m\u001b[34m(self, y)\u001b[39m\n\u001b[32m    829\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_y_class_weight\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[32m--> \u001b[39m\u001b[32m830\u001b[39m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    832\u001b[39m     y = np.copy(y)\n\u001b[32m    833\u001b[39m     expanded_class_weight = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projetos/py_imputation/.venv/lib/python3.12/site-packages/sklearn/utils/multiclass.py:221\u001b[39m, in \u001b[36mcheck_classification_targets\u001b[39m\u001b[34m(y)\u001b[39m\n\u001b[32m    213\u001b[39m y_type = type_of_target(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[32m    215\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    216\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    219\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmultilabel-sequences\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    220\u001b[39m ]:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    222\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Maybe you are trying to fit a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    223\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mclassifier, which expects discrete classes on a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    224\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mregression target with continuous values.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    225\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "\n",
    "# 1. Carregar dados\n",
    "file_path = 'data/glass.data'\n",
    "columns = ['Id','RI','Na','Mg','Al','Si','K','Ca','Ba','Fe','Type_of_glass']\n",
    "df = pd.read_csv(file_path, header=None, names=columns)\n",
    "df.drop(columns=['Id'], inplace=True)\n",
    "\n",
    "# 2. Backup original\n",
    "df_original = df.copy()\n",
    "\n",
    "# 3. Inserir valores ausentes na coluna categórica\n",
    "random.seed(42)\n",
    "missing_indices = df.sample(frac=0.2, random_state=42).index\n",
    "df.loc[missing_indices, 'Type_of_glass'] = np.nan\n",
    "\n",
    "# 4. Separar X e y\n",
    "X = df.drop(columns=['Type_of_glass'])\n",
    "y = df['Type_of_glass']\n",
    "\n",
    "# 5. Transformar y para numérico (caso não seja)\n",
    "y_encoded = y.copy()\n",
    "if y.dtype == object or y.dtype.name == 'category':\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "else:\n",
    "    y_encoded = y\n",
    "\n",
    "# 6. Concatenar para imputação\n",
    "df_imp = X.copy()\n",
    "df_imp['Type_of_glass'] = y_encoded\n",
    "\n",
    "# 7. Imputar usando IterativeImputer com RandomForestClassifier\n",
    "# Como é categórico, usamos Round para garantir valores inteiros\n",
    "imputer = IterativeImputer(estimator=RandomForestClassifier(), \n",
    "                           max_iter=10, random_state=42, \n",
    "                           sample_posterior=False)\n",
    "\n",
    "df_imp_imputed = imputer.fit_transform(df_imp)\n",
    "\n",
    "# 8. Recuperar o dataframe com imputação aplicada\n",
    "df_imputed = pd.DataFrame(df_imp_imputed, columns=df_imp.columns)\n",
    "\n",
    "# 9. Arredondar coluna alvo imputada e converter para int\n",
    "df_imputed['Type_of_glass'] = df_imputed['Type_of_glass'].round().astype(int)\n",
    "\n",
    "# 10. (Opcional) Reverter LabelEncoder se foi usado\n",
    "if 'le' in locals():\n",
    "    df_imputed['Type_of_glass'] = le.inverse_transform(df_imputed['Type_of_glass'])\n",
    "\n",
    "# 11. Comparar original vs imputado (apenas nas posições que estavam ausentes)\n",
    "acertos = (df_imputed.loc[missing_indices, 'Type_of_glass'].values == df_original.loc[missing_indices, 'Type_of_glass'].values)\n",
    "taxa_acerto = np.mean(acertos)\n",
    "print(f\"Taxa de acerto da imputação: {taxa_acerto:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f1728c",
   "metadata": {},
   "source": [
    "### NÂO FAZ SENTIDO USAR MICE!\n",
    "\n",
    "Por que não faz sentido usar MICE para uma única coluna?\n",
    "O MICE é um método desenhado para múltiplas variáveis com valores ausentes, que se influenciam mutuamente. Quando apenas uma coluna possui valores faltantes:\n",
    "\n",
    "- Um modelo supervisionado simples (como RandomForestClassifier, KNN, LogisticRegression, etc.) é mais eficiente e direto.\n",
    "\n",
    "- O MICE se torna desnecessariamente complexo, pois ele simula um processo iterativo em que várias colunas seriam alternadamente \"alvo\" e \"features\", o que não ocorre quando há apenas uma com NaN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951016cb",
   "metadata": {},
   "source": [
    "---\n",
    "O erro de \"label type continuous\" ao usar MICE com IterativeImputer e RandomForestClassifier acontece justamente porque:\n",
    "\n",
    "O IterativeImputer espera que o estimador (o modelo que você passa) lide com os dados da coluna como se fossem contínuos (regressão), mas você está passando um classificador que precisa de rótulos categóricos e inteiros, sem valores ausentes no target.\n",
    "\n",
    "Como só há uma coluna categórica com valores ausentes, o IterativeImputer tenta tratar tudo como contínuo e falha na hora de encaixar o classificador para essa coluna.\n",
    "\n",
    "Além disso, o método é pensado para imputar várias colunas faltantes em sequência, não só uma.\n",
    "\n",
    "Oso do MICE com IterativeImputer e RandomForestClassifier numa única coluna categórica com NaN é a causa dos erros!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
